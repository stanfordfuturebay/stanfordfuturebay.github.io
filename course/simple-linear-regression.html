<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>3.3 Simple linear regression | Shaping the Future of the Bay Area: Intro to Urban Data Analytics in R</title>
  <meta name="description" content="3.3 Simple linear regression | Shaping the Future of the Bay Area: Intro to Urban Data Analytics in R" />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="3.3 Simple linear regression | Shaping the Future of the Bay Area: Intro to Urban Data Analytics in R" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="3.3 Simple linear regression | Shaping the Future of the Bay Area: Intro to Urban Data Analytics in R" />
  
  
  

<meta name="author" content="Stanford Future Bay Initiative" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="monte-carlo-simulations.html"/>
<link rel="next" href="sampling-bias.html"/>
<script src="libs/header-attrs-2.3/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<link href="libs/pagedtable-1.1/css/pagedtable.css" rel="stylesheet" />
<script src="libs/pagedtable-1.1/js/pagedtable.js"></script>
<script src="libs/htmlwidgets-1.5.1/htmlwidgets.js"></script>
<script src="libs/plotly-binding-4.9.2.1/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.1.0.1/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.1.0.1/js/crosstalk.min.js"></script>
<link href="libs/plotly-htmlwidgets-css-1.52.2/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main-1.52.2/plotly-latest.min.js"></script>
<link href="libs/leaflet-1.3.1/leaflet.css" rel="stylesheet" />
<script src="libs/leaflet-1.3.1/leaflet.js"></script>
<link href="libs/leafletfix-1.0.0/leafletfix.css" rel="stylesheet" />
<script src="libs/Proj4Leaflet-1.0.1/proj4-compressed.js"></script>
<script src="libs/Proj4Leaflet-1.0.1/proj4leaflet.js"></script>
<link href="libs/rstudio_leaflet-1.3.1/rstudio_leaflet.css" rel="stylesheet" />
<script src="libs/leaflet-binding-2.0.3/leaflet.js"></script>
<script src="libs/leaflet-providers-1.9.0/leaflet-providers_1.9.0.js"></script>
<script src="libs/leaflet-providers-plugin-2.0.3/leaflet-providers-plugin.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="https://bay.stanford.edu">Stanford Future Bay Initiative</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="software-setup.html"><a href="software-setup.html"><i class="fa fa-check"></i><b>1.1</b> Software Setup</a></li>
<li class="chapter" data-level="1.2" data-path="rstudio-interface.html"><a href="rstudio-interface.html"><i class="fa fa-check"></i><b>1.2</b> RStudio Interface</a></li>
<li class="chapter" data-level="1.3" data-path="r-markdown-files.html"><a href="r-markdown-files.html"><i class="fa fa-check"></i><b>1.3</b> R Markdown Files</a></li>
<li class="chapter" data-level="1.4" data-path="github.html"><a href="github.html"><i class="fa fa-check"></i><b>1.4</b> GitHub</a></li>
<li class="chapter" data-level="1.5" data-path="reading-and-saving-files.html"><a href="reading-and-saving-files.html"><i class="fa fa-check"></i><b>1.5</b> Reading and saving files</a></li>
<li class="chapter" data-level="1.6" data-path="loops.html"><a href="loops.html"><i class="fa fa-check"></i><b>1.6</b> Loops</a></li>
<li class="chapter" data-level="1.7" data-path="manipulating-data.html"><a href="manipulating-data.html"><i class="fa fa-check"></i><b>1.7</b> Manipulating data</a></li>
<li class="chapter" data-level="1.8" data-path="plots.html"><a href="plots.html"><i class="fa fa-check"></i><b>1.8</b> Plots</a></li>
<li class="chapter" data-level="1.9" data-path="geospatial-data.html"><a href="geospatial-data.html"><i class="fa fa-check"></i><b>1.9</b> Geospatial data</a></li>
<li class="chapter" data-level="1.10" data-path="assignment-1.html"><a href="assignment-1.html"><i class="fa fa-check"></i><b>1.10</b> Assignment 1</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="populations.html"><a href="populations.html"><i class="fa fa-check"></i><b>2</b> Populations</a>
<ul>
<li class="chapter" data-level="2.1" data-path="census-data.html"><a href="census-data.html"><i class="fa fa-check"></i><b>2.1</b> Census data</a></li>
<li class="chapter" data-level="2.2" data-path="equity-analysis.html"><a href="equity-analysis.html"><i class="fa fa-check"></i><b>2.2</b> Equity analysis</a></li>
<li class="chapter" data-level="2.3" data-path="migration.html"><a href="migration.html"><i class="fa fa-check"></i><b>2.3</b> Migration</a></li>
<li class="chapter" data-level="2.4" data-path="microdata.html"><a href="microdata.html"><i class="fa fa-check"></i><b>2.4</b> Microdata</a></li>
<li class="chapter" data-level="2.5" data-path="spatial-subsets.html"><a href="spatial-subsets.html"><i class="fa fa-check"></i><b>2.5</b> Spatial subsets</a></li>
<li class="chapter" data-level="2.6" data-path="assignment-2.html"><a href="assignment-2.html"><i class="fa fa-check"></i><b>2.6</b> Assignment 2</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="statistics-part-1.html"><a href="statistics-part-1.html"><i class="fa fa-check"></i><b>3</b> Statistics, Part 1</a>
<ul>
<li class="chapter" data-level="3.1" data-path="probability-distributions.html"><a href="probability-distributions.html"><i class="fa fa-check"></i><b>3.1</b> Probability distributions</a></li>
<li class="chapter" data-level="3.2" data-path="monte-carlo-simulations.html"><a href="monte-carlo-simulations.html"><i class="fa fa-check"></i><b>3.2</b> Monte Carlo simulations</a></li>
<li class="chapter" data-level="3.3" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html"><i class="fa fa-check"></i><b>3.3</b> Simple linear regression</a></li>
<li class="chapter" data-level="3.4" data-path="sampling-bias.html"><a href="sampling-bias.html"><i class="fa fa-check"></i><b>3.4</b> Sampling bias</a></li>
<li class="chapter" data-level="3.5" data-path="multiple-regression.html"><a href="multiple-regression.html"><i class="fa fa-check"></i><b>3.5</b> Multiple regression</a></li>
<li class="chapter" data-level="3.6" data-path="assignment-3.html"><a href="assignment-3.html"><i class="fa fa-check"></i><b>3.6</b> Assignment 3</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="statistics-part-2.html"><a href="statistics-part-2.html"><i class="fa fa-check"></i><b>4</b> Statistics, Part 2</a>
<ul>
<li class="chapter" data-level="4.1" data-path="logistic-regression.html"><a href="logistic-regression.html"><i class="fa fa-check"></i><b>4.1</b> Logistic regression</a></li>
<li class="chapter" data-level="4.2" data-path="training-and-testing-data.html"><a href="training-and-testing-data.html"><i class="fa fa-check"></i><b>4.2</b> Training and testing data</a></li>
<li class="chapter" data-level="4.3" data-path="matching.html"><a href="matching.html"><i class="fa fa-check"></i><b>4.3</b> Matching</a></li>
<li class="chapter" data-level="4.4" data-path="difference-in-differences.html"><a href="difference-in-differences.html"><i class="fa fa-check"></i><b>4.4</b> Difference-in-differences</a></li>
<li class="chapter" data-level="4.5" data-path="assignment-4.html"><a href="assignment-4.html"><i class="fa fa-check"></i><b>4.5</b> Assignment 4</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="mobility.html"><a href="mobility.html"><i class="fa fa-check"></i><b>5</b> Mobility</a>
<ul>
<li class="chapter" data-level="5.1" data-path="travel-survey-data.html"><a href="travel-survey-data.html"><i class="fa fa-check"></i><b>5.1</b> Travel survey data</a></li>
<li class="chapter" data-level="5.2" data-path="commute-data.html"><a href="commute-data.html"><i class="fa fa-check"></i><b>5.2</b> Commute data</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Shaping the Future of the Bay Area: Intro to Urban Data Analytics in R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="simple-linear-regression" class="section level2" number="3.3">
<h2><span class="header-section-number">3.3</span> Simple linear regression</h2>
<p>This section will not serve as a replacement for a more formal mathematical introduction to regression, but may be a good complement that lets us “peek under the hood” with some real data. You should be familiar with the idea that regression is associated with the trendline that Excel allows one to add to a scatter plot. Let’s go ahead and see how to set that up in R, and then inspect the result more closely. For our demonstration, let’s return to ACS data and compare two different variables in the Bay Area at the block group level. A regression analysis could be conceptually similar to an equity analysis as we practiced in Chapter 2, so let’s construct a similar measure. One of our equity analysis examples was comparing income vs. race. For the simple linear regression version, we need to distill both income and race into one-dimensional measures, like “% of households making $100,000 or more” and “% of households that are White Alone”, and collect these values at a granular level, in this case Census tracts in the Bay Area.</p>
<div class="sourceCode" id="cb135"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb135-1"><a href="simple-linear-regression.html#cb135-1"></a><span class="kw">library</span>(tidyverse)</span>
<span id="cb135-2"><a href="simple-linear-regression.html#cb135-2"></a><span class="kw">library</span>(censusapi)</span>
<span id="cb135-3"><a href="simple-linear-regression.html#cb135-3"></a></span>
<span id="cb135-4"><a href="simple-linear-regression.html#cb135-4"></a><span class="kw">Sys.setenv</span>(<span class="dt">CENSUS_KEY=</span><span class="st">&quot;c8aa67e4086b4b5ce3a8717f59faa9a28f611dab&quot;</span>)</span>
<span id="cb135-5"><a href="simple-linear-regression.html#cb135-5"></a></span>
<span id="cb135-6"><a href="simple-linear-regression.html#cb135-6"></a>acs_vars_<span class="dv">2018</span>_5yr &lt;-</span>
<span id="cb135-7"><a href="simple-linear-regression.html#cb135-7"></a><span class="st">  </span><span class="kw">listCensusMetadata</span>(</span>
<span id="cb135-8"><a href="simple-linear-regression.html#cb135-8"></a>    <span class="dt">name =</span> <span class="st">&quot;2018/acs/acs5&quot;</span>,</span>
<span id="cb135-9"><a href="simple-linear-regression.html#cb135-9"></a>    <span class="dt">type =</span> <span class="st">&quot;variables&quot;</span></span>
<span id="cb135-10"><a href="simple-linear-regression.html#cb135-10"></a>  )</span></code></pre></div>
<div class="sourceCode" id="cb136"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb136-1"><a href="simple-linear-regression.html#cb136-1"></a>bay_income_race_tract &lt;-<span class="st"> </span></span>
<span id="cb136-2"><a href="simple-linear-regression.html#cb136-2"></a><span class="st">  </span><span class="kw">getCensus</span>(</span>
<span id="cb136-3"><a href="simple-linear-regression.html#cb136-3"></a>    <span class="dt">name =</span> <span class="st">&quot;acs/acs5&quot;</span>,</span>
<span id="cb136-4"><a href="simple-linear-regression.html#cb136-4"></a>    <span class="dt">vintage =</span> <span class="dv">2018</span>,</span>
<span id="cb136-5"><a href="simple-linear-regression.html#cb136-5"></a>    <span class="dt">region =</span> <span class="st">&quot;tract:*&quot;</span>,</span>
<span id="cb136-6"><a href="simple-linear-regression.html#cb136-6"></a>    <span class="dt">regionin =</span> <span class="st">&quot;state:06+county:001,013,041,055,075,081,085,095,097&quot;</span>,</span>
<span id="cb136-7"><a href="simple-linear-regression.html#cb136-7"></a>    <span class="dt">vars =</span> <span class="kw">c</span>(</span>
<span id="cb136-8"><a href="simple-linear-regression.html#cb136-8"></a>      <span class="st">&quot;B19001A_001E&quot;</span>,</span>
<span id="cb136-9"><a href="simple-linear-regression.html#cb136-9"></a>      <span class="st">&quot;B19001_001E&quot;</span>,</span>
<span id="cb136-10"><a href="simple-linear-regression.html#cb136-10"></a>      <span class="st">&quot;B19001_014E&quot;</span>,</span>
<span id="cb136-11"><a href="simple-linear-regression.html#cb136-11"></a>      <span class="st">&quot;B19001_015E&quot;</span>,</span>
<span id="cb136-12"><a href="simple-linear-regression.html#cb136-12"></a>      <span class="st">&quot;B19001_016E&quot;</span>,</span>
<span id="cb136-13"><a href="simple-linear-regression.html#cb136-13"></a>      <span class="st">&quot;B19001_017E&quot;</span></span>
<span id="cb136-14"><a href="simple-linear-regression.html#cb136-14"></a>    )</span>
<span id="cb136-15"><a href="simple-linear-regression.html#cb136-15"></a>  ) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb136-16"><a href="simple-linear-regression.html#cb136-16"></a><span class="st">  </span><span class="kw">transmute</span>(</span>
<span id="cb136-17"><a href="simple-linear-regression.html#cb136-17"></a>    <span class="dt">tract =</span> <span class="kw">paste0</span>(state, county, tract),</span>
<span id="cb136-18"><a href="simple-linear-regression.html#cb136-18"></a>    <span class="dt">perc_white =</span> B19001A_001E <span class="op">/</span><span class="st"> </span>B19001_001E,</span>
<span id="cb136-19"><a href="simple-linear-regression.html#cb136-19"></a>    <span class="dt">perc_over100k =</span> (B19001_014E <span class="op">+</span><span class="st"> </span>B19001_015E <span class="op">+</span><span class="st"> </span>B19001_016E <span class="op">+</span><span class="st"> </span>B19001_017E) <span class="op">/</span><span class="st"> </span>B19001_001E</span>
<span id="cb136-20"><a href="simple-linear-regression.html#cb136-20"></a>  ) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb136-21"><a href="simple-linear-regression.html#cb136-21"></a><span class="st">  </span><span class="kw">filter</span>(</span>
<span id="cb136-22"><a href="simple-linear-regression.html#cb136-22"></a>    <span class="op">!</span><span class="kw">is.na</span>(perc_white), </span>
<span id="cb136-23"><a href="simple-linear-regression.html#cb136-23"></a>    <span class="op">!</span><span class="kw">is.na</span>(perc_over100k)</span>
<span id="cb136-24"><a href="simple-linear-regression.html#cb136-24"></a>  )</span></code></pre></div>
<p>Note that because we are working with average values from the ACS for a certain geography, in this case Census tracts, we should consider an <a href="https://en.wikipedia.org/wiki/Ecological_fallacy">ecological inference problem</a> when interpreting our results. It’s possible that just looking at average statistics for a Census tract is masking an underlying relationship between income and race at the individual household level. We’ll try to account for this later when we switch to household-level PUMS data.</p>
<p>Let’s first plot this data as a scatter plot using <code>geom_point()</code> in <code>ggplot</code>:</p>
<div class="sourceCode" id="cb137"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb137-1"><a href="simple-linear-regression.html#cb137-1"></a><span class="kw">ggplot</span>() <span class="op">+</span></span>
<span id="cb137-2"><a href="simple-linear-regression.html#cb137-2"></a><span class="st">  </span><span class="kw">geom_point</span>(</span>
<span id="cb137-3"><a href="simple-linear-regression.html#cb137-3"></a>    <span class="dt">data =</span> bay_income_race_tract,</span>
<span id="cb137-4"><a href="simple-linear-regression.html#cb137-4"></a>    <span class="kw">aes</span>(</span>
<span id="cb137-5"><a href="simple-linear-regression.html#cb137-5"></a>      <span class="dt">x =</span> perc_white,</span>
<span id="cb137-6"><a href="simple-linear-regression.html#cb137-6"></a>      <span class="dt">y =</span> perc_over100k</span>
<span id="cb137-7"><a href="simple-linear-regression.html#cb137-7"></a>    )</span>
<span id="cb137-8"><a href="simple-linear-regression.html#cb137-8"></a>  )</span></code></pre></div>
<p><img src="course_files/figure-html/unnamed-chunk-107-1.png" width="672" /></p>
<p>Now let’s add a regression line using the built-in capabilities of <code>ggplot</code>, specifically <code>geom_smooth()</code> with the argument <code>method = “lm”</code> which stands for “linear model”. Note that in this case, since we want both <code>geom_point()</code> and <code>geom_smooth()</code> to refer to the same data, we move the <code>data =</code> and <code>aes()</code> arguments within <code>ggplot()</code> itself, which is like turning this specific frame of the data into the object in the pipeline.</p>
<div class="sourceCode" id="cb138"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb138-1"><a href="simple-linear-regression.html#cb138-1"></a><span class="kw">ggplot</span>(</span>
<span id="cb138-2"><a href="simple-linear-regression.html#cb138-2"></a>  <span class="dt">data =</span> bay_income_race_tract,</span>
<span id="cb138-3"><a href="simple-linear-regression.html#cb138-3"></a>  <span class="kw">aes</span>(</span>
<span id="cb138-4"><a href="simple-linear-regression.html#cb138-4"></a>      <span class="dt">x =</span> perc_white,</span>
<span id="cb138-5"><a href="simple-linear-regression.html#cb138-5"></a>      <span class="dt">y =</span> perc_over100k</span>
<span id="cb138-6"><a href="simple-linear-regression.html#cb138-6"></a>    )</span>
<span id="cb138-7"><a href="simple-linear-regression.html#cb138-7"></a>) <span class="op">+</span></span>
<span id="cb138-8"><a href="simple-linear-regression.html#cb138-8"></a><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span></span>
<span id="cb138-9"><a href="simple-linear-regression.html#cb138-9"></a><span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>)</span></code></pre></div>
<p><img src="course_files/figure-html/unnamed-chunk-108-1.png" width="672" /></p>
<p>The default method for <code>geom_smooth()</code> happens to be a more complicated technique called LOESS (locally estimated scatterplot smoothing), but we’ll focus for now on the simple linear version. So how exactly is the “regression line” determined? By definition, the regression line is positioned such that it minimizes the “sum of squares of residuals” (SSR), where residuals are the vertical distances between each scatter plot point and the regression line itself. Let’s try directly calculating this SSR value with a different potential “best fit line” which has a slope 0 and a y-intercept at the mean of the y-axis values. From there, we’ll populate <code>best_fit_candidate</code> with paired values for every actual y-value in the real data, but because this candidate line is a straight horizontal line, every paired value will just be the same as the y-intercept. Then, we’ll calculate the <code>residuals</code> as the difference between each pair of y-values, and take the sum of squares of all residuals.</p>
<div class="sourceCode" id="cb139"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb139-1"><a href="simple-linear-regression.html#cb139-1"></a>slope &lt;-<span class="st"> </span><span class="dv">0</span></span>
<span id="cb139-2"><a href="simple-linear-regression.html#cb139-2"></a>yintercept &lt;-<span class="st"> </span><span class="kw">mean</span>(bay_income_race_tract<span class="op">$</span>perc_over100k)</span>
<span id="cb139-3"><a href="simple-linear-regression.html#cb139-3"></a></span>
<span id="cb139-4"><a href="simple-linear-regression.html#cb139-4"></a>best_fit_candidate &lt;-<span class="st"> </span>slope <span class="op">*</span><span class="st"> </span>bay_income_race_tract<span class="op">$</span>perc_white <span class="op">+</span><span class="st"> </span>yintercept </span>
<span id="cb139-5"><a href="simple-linear-regression.html#cb139-5"></a></span>
<span id="cb139-6"><a href="simple-linear-regression.html#cb139-6"></a>residuals &lt;-<span class="st"> </span>bay_income_race_tract<span class="op">$</span>perc_over100k <span class="op">-</span><span class="st"> </span>best_fit_candidate</span>
<span id="cb139-7"><a href="simple-linear-regression.html#cb139-7"></a></span>
<span id="cb139-8"><a href="simple-linear-regression.html#cb139-8"></a>sumsq_residuals &lt;-<span class="st"> </span><span class="kw">sum</span>(residuals<span class="op">^</span><span class="dv">2</span>)</span>
<span id="cb139-9"><a href="simple-linear-regression.html#cb139-9"></a></span>
<span id="cb139-10"><a href="simple-linear-regression.html#cb139-10"></a>sumsq_residuals</span></code></pre></div>
<pre><code>## [1] 52.26937</code></pre>
<p>And here’s a plot showing this poor “best fit candidate” in comparison to the actual best fit line according to <code>geom_smooth()</code>:</p>
<div class="sourceCode" id="cb141"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb141-1"><a href="simple-linear-regression.html#cb141-1"></a><span class="kw">ggplot</span>(</span>
<span id="cb141-2"><a href="simple-linear-regression.html#cb141-2"></a>  <span class="dt">data =</span> bay_income_race_tract,</span>
<span id="cb141-3"><a href="simple-linear-regression.html#cb141-3"></a>  <span class="kw">aes</span>(</span>
<span id="cb141-4"><a href="simple-linear-regression.html#cb141-4"></a>      <span class="dt">x =</span> perc_white,</span>
<span id="cb141-5"><a href="simple-linear-regression.html#cb141-5"></a>      <span class="dt">y =</span> perc_over100k</span>
<span id="cb141-6"><a href="simple-linear-regression.html#cb141-6"></a>    )</span>
<span id="cb141-7"><a href="simple-linear-regression.html#cb141-7"></a>) <span class="op">+</span></span>
<span id="cb141-8"><a href="simple-linear-regression.html#cb141-8"></a><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span></span>
<span id="cb141-9"><a href="simple-linear-regression.html#cb141-9"></a><span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>) <span class="op">+</span></span>
<span id="cb141-10"><a href="simple-linear-regression.html#cb141-10"></a><span class="st">  </span><span class="kw">geom_line</span>(</span>
<span id="cb141-11"><a href="simple-linear-regression.html#cb141-11"></a>    <span class="kw">aes</span>(</span>
<span id="cb141-12"><a href="simple-linear-regression.html#cb141-12"></a>      <span class="dt">x =</span> bay_income_race_tract<span class="op">$</span>perc_white,</span>
<span id="cb141-13"><a href="simple-linear-regression.html#cb141-13"></a>      <span class="dt">y =</span> best_fit_candidate</span>
<span id="cb141-14"><a href="simple-linear-regression.html#cb141-14"></a>    ),</span>
<span id="cb141-15"><a href="simple-linear-regression.html#cb141-15"></a>    <span class="dt">color =</span> <span class="st">&quot;red&quot;</span>,</span>
<span id="cb141-16"><a href="simple-linear-regression.html#cb141-16"></a>    <span class="dt">size =</span> <span class="dv">1</span></span>
<span id="cb141-17"><a href="simple-linear-regression.html#cb141-17"></a>  )</span></code></pre></div>
<p><img src="course_files/figure-html/unnamed-chunk-110-1.png" width="672" /></p>
<p>If this straight horizontal line yields a SSR of 52, then the actual best fit line must be able to produce a lower SSR. If we didn’t have <code>geom_smooth()</code> to give us the best fit line directly, we could try to use optimization techniques in R to discover the slope and y-intercept of the best fit line. To do this, let’s first turn the code we previously used into a function. We haven’t explicitly done this yet in the curriculum, but this technique is generally available wherever you think it increases clarity of the code or reduces the amount of repetitive writing you have to do. For example, anywhere we’ve used a <code>map()</code> function from <code>purrr</code> in <code>tidyverse</code>, we could have pre-created a function that does the steps within <code>map()</code>. Anyway, here’s the functionalized version of the math we did previously:</p>
<div class="sourceCode" id="cb142"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb142-1"><a href="simple-linear-regression.html#cb142-1"></a>get_sumsq_residuals &lt;-<span class="st"> </span><span class="cf">function</span>(x){</span>
<span id="cb142-2"><a href="simple-linear-regression.html#cb142-2"></a></span>
<span id="cb142-3"><a href="simple-linear-regression.html#cb142-3"></a>  slope &lt;-<span class="st"> </span>x[<span class="dv">1</span>]</span>
<span id="cb142-4"><a href="simple-linear-regression.html#cb142-4"></a>  yintercept &lt;-<span class="st"> </span>x[<span class="dv">2</span>]</span>
<span id="cb142-5"><a href="simple-linear-regression.html#cb142-5"></a>  </span>
<span id="cb142-6"><a href="simple-linear-regression.html#cb142-6"></a>  best_fit_candidate &lt;-<span class="st"> </span>slope <span class="op">*</span><span class="st"> </span>bay_income_race_tract<span class="op">$</span>perc_white <span class="op">+</span><span class="st"> </span>yintercept </span>
<span id="cb142-7"><a href="simple-linear-regression.html#cb142-7"></a>  </span>
<span id="cb142-8"><a href="simple-linear-regression.html#cb142-8"></a>  residuals &lt;-<span class="st"> </span>bay_income_race_tract<span class="op">$</span>perc_over100k <span class="op">-</span><span class="st"> </span>best_fit_candidate</span>
<span id="cb142-9"><a href="simple-linear-regression.html#cb142-9"></a>  </span>
<span id="cb142-10"><a href="simple-linear-regression.html#cb142-10"></a>  sumsq_residuals &lt;-<span class="st"> </span><span class="kw">sum</span>(residuals<span class="op">^</span><span class="dv">2</span>)</span>
<span id="cb142-11"><a href="simple-linear-regression.html#cb142-11"></a>}</span></code></pre></div>
<p>The name <code>get_sumsq_residuals</code> is up to you, just like naming a data object. After running the chunk above, <code>get_sumsq_residuals()</code> wasn’t actually applied to anything, but it is now available to you to use, just like any function we’ve used so far. Whatever argument you provide to <code>get_sumsq_residuals()</code> is then used in the way <code>x</code> is used in the function definition. Note that <code>x</code> actually needs two values within it, which are then used as <code>slope</code> and <code>yintercept</code>, so if you supply an incorrect data structure as <code>x</code>, an error will be triggered. You will get back the value of <code>sumsq_residuals</code> if everything runs correctly; this is because it’s the last line in the function, though you can always clarify what you want returned using <code>return()</code>.</p>
<p>Now let’s use <code>optim()</code> to let R search for the best two values, <code>x[1]</code> and <code>x[2]</code>, given the goal of minimizing the result of <code>get_sumsq_residuals()</code>. Similar to “Goal Seek” in Excel, the function will search through a range of numerical options for <code>x[1]</code> and <code>x[2]</code>. <code>optimize()</code> is the simpler version that optimizes based on a single variable, but here we use <code>optim()</code> to deal with two changing variables, and <code>optim()</code> requires the input to be written as a <code>c()</code> vector, hence the specific structure of <code>get_sumsq_residuals()</code> receiving one vectorized argument.</p>
<div class="sourceCode" id="cb143"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb143-1"><a href="simple-linear-regression.html#cb143-1"></a>optimization &lt;-<span class="st"> </span><span class="kw">optim</span>(<span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">0</span>), get_sumsq_residuals)</span>
<span id="cb143-2"><a href="simple-linear-regression.html#cb143-2"></a></span>
<span id="cb143-3"><a href="simple-linear-regression.html#cb143-3"></a>optimization</span></code></pre></div>
<pre><code>## $par
## [1] 0.2477757 0.3483216
## 
## $value
## [1] 47.42104
## 
## $counts
## function gradient 
##       61       NA 
## 
## $convergence
## [1] 0
## 
## $message
## NULL</code></pre>
<p>The output <code>optimization</code> is a list of various potentially useful metrics. <code>optimization$par</code> is the specific pair of results for <code>slope</code> and <code>y-intercept</code>, and <code>optimization$value</code> is the minimized SSR, which we can see is less than our previous attempt. Let’s now directly plot the “best fit line” based on this optimization result and see if it matches the automatic result from <code>geom_smooth()</code>:</p>
<div class="sourceCode" id="cb145"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb145-1"><a href="simple-linear-regression.html#cb145-1"></a><span class="kw">ggplot</span>(</span>
<span id="cb145-2"><a href="simple-linear-regression.html#cb145-2"></a>  <span class="dt">data =</span> bay_income_race_tract,</span>
<span id="cb145-3"><a href="simple-linear-regression.html#cb145-3"></a>  <span class="kw">aes</span>(</span>
<span id="cb145-4"><a href="simple-linear-regression.html#cb145-4"></a>      <span class="dt">x =</span> perc_white,</span>
<span id="cb145-5"><a href="simple-linear-regression.html#cb145-5"></a>      <span class="dt">y =</span> perc_over100k</span>
<span id="cb145-6"><a href="simple-linear-regression.html#cb145-6"></a>    )</span>
<span id="cb145-7"><a href="simple-linear-regression.html#cb145-7"></a>) <span class="op">+</span></span>
<span id="cb145-8"><a href="simple-linear-regression.html#cb145-8"></a><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span></span>
<span id="cb145-9"><a href="simple-linear-regression.html#cb145-9"></a><span class="st">  </span><span class="kw">geom_line</span>(</span>
<span id="cb145-10"><a href="simple-linear-regression.html#cb145-10"></a>    <span class="kw">aes</span>(</span>
<span id="cb145-11"><a href="simple-linear-regression.html#cb145-11"></a>      <span class="dt">x =</span> perc_white,</span>
<span id="cb145-12"><a href="simple-linear-regression.html#cb145-12"></a>      <span class="dt">y =</span> perc_white <span class="op">*</span><span class="st"> </span>optimization<span class="op">$</span>par[<span class="dv">1</span>] <span class="op">+</span><span class="st"> </span>optimization<span class="op">$</span>par[<span class="dv">2</span>]</span>
<span id="cb145-13"><a href="simple-linear-regression.html#cb145-13"></a>    ),</span>
<span id="cb145-14"><a href="simple-linear-regression.html#cb145-14"></a>    <span class="dt">color =</span> <span class="st">&quot;blue&quot;</span>,</span>
<span id="cb145-15"><a href="simple-linear-regression.html#cb145-15"></a>    <span class="dt">size =</span> <span class="dv">1</span></span>
<span id="cb145-16"><a href="simple-linear-regression.html#cb145-16"></a>  )</span></code></pre></div>
<p><img src="course_files/figure-html/unnamed-chunk-113-1.png" width="672" /></p>
<p>Now that you’ve produced the regression line from scratch, you should feel comfortable trusting R’s regression lines. However, keep in mind from your general understanding of regression models that they are only valid if a set of conditions are true about the data, including that the mean of the residuals is ~ 0, and that the residuals are normally distributed.</p>
<div class="sourceCode" id="cb146"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb146-1"><a href="simple-linear-regression.html#cb146-1"></a>slope &lt;-<span class="st"> </span>optimization<span class="op">$</span>par[<span class="dv">1</span>]</span>
<span id="cb146-2"><a href="simple-linear-regression.html#cb146-2"></a>yintercept &lt;-<span class="st"> </span>optimization<span class="op">$</span>par[<span class="dv">2</span>]</span>
<span id="cb146-3"><a href="simple-linear-regression.html#cb146-3"></a></span>
<span id="cb146-4"><a href="simple-linear-regression.html#cb146-4"></a>best_fit_candidate &lt;-<span class="st"> </span>slope <span class="op">*</span><span class="st"> </span>bay_income_race_tract<span class="op">$</span>perc_white <span class="op">+</span><span class="st"> </span>yintercept </span>
<span id="cb146-5"><a href="simple-linear-regression.html#cb146-5"></a></span>
<span id="cb146-6"><a href="simple-linear-regression.html#cb146-6"></a>residuals &lt;-<span class="st"> </span>bay_income_race_tract<span class="op">$</span>perc_over100k <span class="op">-</span><span class="st"> </span>best_fit_candidate</span>
<span id="cb146-7"><a href="simple-linear-regression.html#cb146-7"></a></span>
<span id="cb146-8"><a href="simple-linear-regression.html#cb146-8"></a><span class="kw">mean</span>(residuals)</span></code></pre></div>
<pre><code>## [1] -1.541715e-05</code></pre>
<div class="sourceCode" id="cb148"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb148-1"><a href="simple-linear-regression.html#cb148-1"></a><span class="kw">plot</span>(<span class="kw">density</span>(residuals))</span></code></pre></div>
<p><img src="course_files/figure-html/unnamed-chunk-114-1.png" width="672" /></p>
<p>The mean of the residual is essentially zero, but there appears to be a slight skew to the density curve for the residuals, which might mean that we don’t have the conditions necessary to meaningfully interpret regression results on the data. However, this particular distribution does not look significantly skewed. Many other robust tests for normality are available should your work entail them.</p>
<p>Besides plotting with <code>ggplot</code>, which is always recommended if you’re working with two continuous variables so you can visually inspect the distribution of data, the formal function for regression analysis is <code>lm()</code>, which is used as follows. If you are familiar with the <code>y = mx + b</code> framing of the regression line, then think of <code>y</code> as the variable you are trying to predict using the <code>x</code> information. Another common way of describing this is that <code>y</code> is the dependent variable, and <code>x</code> is the independent variable. In <code>lm()</code>, the first argument is a specific arrangement where the <code>y</code> variable field name is provided before the <code>~</code>, and the <code>x</code> variable field name is provided after the <code>~</code> (when we move on to multiple regression, you’ll add additional <code>x</code> variables after the <code>~</code>). The second necessary argument to <code>lm()</code> is the overall dataframe.</p>
<div class="sourceCode" id="cb149"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb149-1"><a href="simple-linear-regression.html#cb149-1"></a>model &lt;-<span class="st"> </span><span class="kw">lm</span>(perc_over100k <span class="op">~</span><span class="st"> </span>perc_white, bay_income_race_tract)</span>
<span id="cb149-2"><a href="simple-linear-regression.html#cb149-2"></a></span>
<span id="cb149-3"><a href="simple-linear-regression.html#cb149-3"></a><span class="kw">summary</span>(model)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = perc_over100k ~ perc_white, data = bay_income_race_tract)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.48224 -0.13429  0.00815  0.12613  0.50205 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  0.34838    0.01202   28.99   &lt;2e-16 ***
## perc_white   0.24765    0.01952   12.69   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.1735 on 1575 degrees of freedom
## Multiple R-squared:  0.09276,    Adjusted R-squared:  0.09218 
## F-statistic:   161 on 1 and 1575 DF,  p-value: &lt; 2.2e-16</code></pre>
<p><code>model</code> holds a lot of information about the regression analysis, and <code>summary(model)</code> is a common way to output results, though you may not necessarily need every single metric provided (depending on how technical your statistical experience is). I’ll describe what I tend to focus on when I view this kind of summary output:</p>
<ul>
<li>It’s generally good to see that the Residuals (also accessible in full through <code>model$residuals</code>) are centered on 0 and have roughly symmetrical distribution, which are just other signals of the same findings from our previous chunk’s approach.</li>
<li><code>model$coefficients</code> gets you the same information as we got from our manual optimization function.</li>
<li>The standard error for the slope coefficient, in this case a standard error of 0.0195156 on the slope of 0.2476469, is important. Think of it as a measure of uncertainty about the slope of the line. Usually the fundamental question we’re asking when doing a simple linear regression is: Does the specific best fit line through our sample data seem to suggest that the “true best fit line” for the whole population is something other than a flat line (similar to our previous example)? The “0” assumption is called the “null hypothesis”, which is basically the starting assumption that there is no relationship between the <code>x</code> and <code>y</code> values (i.e. knowing information about <code>x</code> does not give us any predictive power on <code>y</code>). But if our particular scatter plot seems to show a non-zero relationship, and the likelihood of an “off-chance sampling” from a full population that conforms with the null hypothesis can be measured using standard error and shown to be exceedingly unlikely, then we formally “reject the null hypothesis” and accept this sample-based regression line as reflective of “reality”. That threshold for deciding to reject the null hypothesis is based on the standard error placing the “off-chance sampling” in the tail ends of a normal distribution and is usually an arbitrary low probability like 0.05, which the asterisks in the output refer to, and which the “p-value” (shown here under the heading <code>Pr(&gt;|t|)</code>) is formally being compared against (i.e. if the p-value is less than 0.05, usually that’s sufficient for a scientific experiment’s results to be considered “statistically significant”). If you haven’t encountered this material through a more formal statistics reading, this brief description certainly doesn’t do the topic justice; I am merely doing a cursory review and pointing out where to find common statistical measures that you should build a fuller understanding of through other sources.</li>
<li>“R-squared” is a measure of the shared variance between the <code>x</code> and <code>y</code> values. You could say that “variation in x explains 9.3% of the variation in y”. Sharing 100% of variance would be a perfect prediction. The gap is essentially the “residuals”, and you should always expect a gap when dealing with social data because, as we’d expect, everything can have myriad influences in all kinds of directions.</li>
</ul>
<p>Keep in mind that none of these results should be interpreted as having anything to do with causation; regression analyses should be put squarely in the “correlation” category of analysis (we’ll consider causal inference in the next chapter). All we’re looking at are relationships between observed values. A classic error is to assume that the regression line shows you how much “directly changing <code>x</code>” affects <code>y</code>, but keep in mind that it was entirely up to us which variable we happened to consider <code>x</code> and which one we happened to consider <code>y</code>!</p>
<p>By the way, if you want to make a prediction using this regression model, given a new <code>x</code> value, you can do it as follows:</p>
<div class="sourceCode" id="cb151"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb151-1"><a href="simple-linear-regression.html#cb151-1"></a><span class="kw">predict</span>(model, <span class="kw">data.frame</span>(<span class="dt">perc_white =</span> <span class="fl">0.5</span>))</span></code></pre></div>
<pre><code>##         1 
## 0.4722035</code></pre>
<p><code>predict()</code> receives the <code>model</code> as its first argument, and then can receive a dataframe with a field of <code>x</code> values with the same field name as was used in <code>model</code>. So even though we just want to make one prediction here, given a new Census tract with <code>perc_white = 0.5</code>, we need to feed that in as a dataframe using <code>data.frame()</code>. Also note that if you give no second argument to <code>predict()</code>, it will by default use the original data itself, meaning it will essentially create the same thing as <code>best_fit_candidate</code> from before, with <code>y</code> values for every original <code>x</code> that line up exactly on the regression line.</p>
<p>Now let’s switch to running a simple linear regression with PUMS data. The analysis will be fundamentally different because now we are working with individual-level data. The <code>y</code> values will be the exact income reported by our sample of PUMS individuals on the ACS questionnaire. As for the <code>x</code> value, we will no longer be working with a “% White households” for all households in a Census tract; instead, we will have a categorical “yes” or “no” for whether the individual household has a White householder. The previous scatter plot had continuous variables for both the <code>x</code> and <code>y</code> axis, but generally, you can code binary categories as <code>0</code> or <code>1</code>, which won’t make much sense when viewed as a scatter plot, but can still be interpreted via <code>lm()</code>.</p>
<p>Similar to in Chapter 2.4, let’s use <code>tidycensus</code> to load the PUMS data, picking specific variables for our purposes. Using <code>pums_vars_2018</code> as a data dictionary, I found that <code>RAC1P</code> will provide the race of each individual, and we can treat the first listed respondent from each household (<code>SPORDER == 1</code>, where <code>SPORDER</code> will automatically be provided as part of <code>get_pums()</code>) as the “household race”, so as to match the way the ACS summary data from before was processed. Another PUMS variable, <code>HINCP</code>, will provide household income for each household.</p>
<div class="sourceCode" id="cb153"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb153-1"><a href="simple-linear-regression.html#cb153-1"></a><span class="kw">library</span>(tidycensus)</span>
<span id="cb153-2"><a href="simple-linear-regression.html#cb153-2"></a></span>
<span id="cb153-3"><a href="simple-linear-regression.html#cb153-3"></a><span class="kw">census_api_key</span>(<span class="st">&quot;c8aa67e4086b4b5ce3a8717f59faa9a28f611dab&quot;</span>)</span>
<span id="cb153-4"><a href="simple-linear-regression.html#cb153-4"></a></span>
<span id="cb153-5"><a href="simple-linear-regression.html#cb153-5"></a>pums_vars_<span class="dv">2018</span> &lt;-<span class="st"> </span></span>
<span id="cb153-6"><a href="simple-linear-regression.html#cb153-6"></a><span class="st">  </span>pums_variables <span class="op">%&gt;%</span></span>
<span id="cb153-7"><a href="simple-linear-regression.html#cb153-7"></a><span class="st">  </span><span class="kw">filter</span>(year <span class="op">==</span><span class="st"> </span><span class="dv">2018</span>, survey <span class="op">==</span><span class="st"> &quot;acs5&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb154"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb154-1"><a href="simple-linear-regression.html#cb154-1"></a>ca_pums &lt;-<span class="st"> </span><span class="kw">get_pums</span>(</span>
<span id="cb154-2"><a href="simple-linear-regression.html#cb154-2"></a>  <span class="dt">variables =</span> <span class="kw">c</span>(</span>
<span id="cb154-3"><a href="simple-linear-regression.html#cb154-3"></a>    <span class="st">&quot;PUMA&quot;</span>,</span>
<span id="cb154-4"><a href="simple-linear-regression.html#cb154-4"></a>    <span class="st">&quot;NP&quot;</span>,</span>
<span id="cb154-5"><a href="simple-linear-regression.html#cb154-5"></a>    <span class="st">&quot;RAC1P&quot;</span>,</span>
<span id="cb154-6"><a href="simple-linear-regression.html#cb154-6"></a>    <span class="st">&quot;HINCP&quot;</span></span>
<span id="cb154-7"><a href="simple-linear-regression.html#cb154-7"></a>  ),</span>
<span id="cb154-8"><a href="simple-linear-regression.html#cb154-8"></a>  <span class="dt">state =</span> <span class="st">&quot;CA&quot;</span>,</span>
<span id="cb154-9"><a href="simple-linear-regression.html#cb154-9"></a>  <span class="dt">year =</span> <span class="dv">2018</span>,</span>
<span id="cb154-10"><a href="simple-linear-regression.html#cb154-10"></a>  <span class="dt">survey =</span> <span class="st">&quot;acs5&quot;</span>,</span>
<span id="cb154-11"><a href="simple-linear-regression.html#cb154-11"></a>  <span class="dt">recode =</span> T</span>
<span id="cb154-12"><a href="simple-linear-regression.html#cb154-12"></a>)</span>
<span id="cb154-13"><a href="simple-linear-regression.html#cb154-13"></a></span>
<span id="cb154-14"><a href="simple-linear-regression.html#cb154-14"></a>ca_pumas &lt;-</span>
<span id="cb154-15"><a href="simple-linear-regression.html#cb154-15"></a><span class="st">  </span><span class="kw">pumas</span>(<span class="st">&quot;CA&quot;</span>, <span class="dt">cb =</span> T, <span class="dt">progress_bar =</span> F)</span>
<span id="cb154-16"><a href="simple-linear-regression.html#cb154-16"></a></span>
<span id="cb154-17"><a href="simple-linear-regression.html#cb154-17"></a>bay_county_names &lt;-</span>
<span id="cb154-18"><a href="simple-linear-regression.html#cb154-18"></a><span class="st">  </span><span class="kw">c</span>(</span>
<span id="cb154-19"><a href="simple-linear-regression.html#cb154-19"></a>    <span class="st">&quot;Alameda&quot;</span>,</span>
<span id="cb154-20"><a href="simple-linear-regression.html#cb154-20"></a>    <span class="st">&quot;Contra Costa&quot;</span>,</span>
<span id="cb154-21"><a href="simple-linear-regression.html#cb154-21"></a>    <span class="st">&quot;Marin&quot;</span>,</span>
<span id="cb154-22"><a href="simple-linear-regression.html#cb154-22"></a>    <span class="st">&quot;Napa&quot;</span>,</span>
<span id="cb154-23"><a href="simple-linear-regression.html#cb154-23"></a>    <span class="st">&quot;San Francisco&quot;</span>,</span>
<span id="cb154-24"><a href="simple-linear-regression.html#cb154-24"></a>    <span class="st">&quot;San Mateo&quot;</span>,</span>
<span id="cb154-25"><a href="simple-linear-regression.html#cb154-25"></a>    <span class="st">&quot;Santa Clara&quot;</span>,</span>
<span id="cb154-26"><a href="simple-linear-regression.html#cb154-26"></a>    <span class="st">&quot;Solano&quot;</span>,</span>
<span id="cb154-27"><a href="simple-linear-regression.html#cb154-27"></a>    <span class="st">&quot;Sonoma&quot;</span></span>
<span id="cb154-28"><a href="simple-linear-regression.html#cb154-28"></a>  )</span>
<span id="cb154-29"><a href="simple-linear-regression.html#cb154-29"></a></span>
<span id="cb154-30"><a href="simple-linear-regression.html#cb154-30"></a>bay_counties &lt;-</span>
<span id="cb154-31"><a href="simple-linear-regression.html#cb154-31"></a><span class="st">  </span><span class="kw">counties</span>(<span class="st">&quot;CA&quot;</span>, <span class="dt">cb =</span> T, <span class="dt">progress_bar =</span> F) <span class="op">%&gt;%</span></span>
<span id="cb154-32"><a href="simple-linear-regression.html#cb154-32"></a><span class="st">  </span><span class="kw">filter</span>(NAME <span class="op">%in%</span><span class="st"> </span>bay_county_names)</span>
<span id="cb154-33"><a href="simple-linear-regression.html#cb154-33"></a></span>
<span id="cb154-34"><a href="simple-linear-regression.html#cb154-34"></a>bay_pumas &lt;-</span>
<span id="cb154-35"><a href="simple-linear-regression.html#cb154-35"></a><span class="st">  </span>ca_pumas <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb154-36"><a href="simple-linear-regression.html#cb154-36"></a><span class="st">  </span><span class="kw">st_centroid</span>() <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb154-37"><a href="simple-linear-regression.html#cb154-37"></a><span class="st">  </span>.[bay_counties, ] <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb154-38"><a href="simple-linear-regression.html#cb154-38"></a><span class="st">  </span><span class="kw">st_set_geometry</span>(<span class="ot">NULL</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb154-39"><a href="simple-linear-regression.html#cb154-39"></a><span class="st">  </span><span class="kw">left_join</span>(ca_pumas <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">select</span>(GEOID10)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb154-40"><a href="simple-linear-regression.html#cb154-40"></a><span class="st">  </span><span class="kw">st_as_sf</span>()</span>
<span id="cb154-41"><a href="simple-linear-regression.html#cb154-41"></a></span>
<span id="cb154-42"><a href="simple-linear-regression.html#cb154-42"></a>bay_pums &lt;-</span>
<span id="cb154-43"><a href="simple-linear-regression.html#cb154-43"></a><span class="st">  </span>ca_pums <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb154-44"><a href="simple-linear-regression.html#cb154-44"></a><span class="st">  </span><span class="kw">filter</span>(PUMA <span class="op">%in%</span><span class="st"> </span>bay_pumas<span class="op">$</span>PUMACE10)</span></code></pre></div>
<p>Keep in mind that PUMS data gives you individual respondents, but each respondent will be part of a household identified by <code>SERIALNO</code>, another automatic variable received through <code>get_pums()</code>. There are also weighting variables, <code>WGTP</code> for households and <code>PWGTP</code> for persons. In our case, given our analysis is about household-level race and income, we will filter this dataframe such that each row is one individual household. From there, technically the <code>WGTP</code> should be a signal of how many copies of each row should exist for the dataframe to best represent all households in the full population. We could actually restructure the data to have those duplicate rows, but <code>lm()</code> will be able to account for the weighting information automatically in its regression analysis.</p>
<div class="sourceCode" id="cb155"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb155-1"><a href="simple-linear-regression.html#cb155-1"></a>bay_pums_regression &lt;-</span>
<span id="cb155-2"><a href="simple-linear-regression.html#cb155-2"></a><span class="st">  </span>bay_pums <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb155-3"><a href="simple-linear-regression.html#cb155-3"></a><span class="st">  </span><span class="kw">filter</span>(SPORDER <span class="op">==</span><span class="st"> </span><span class="dv">1</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb155-4"><a href="simple-linear-regression.html#cb155-4"></a><span class="st">  </span><span class="kw">mutate</span>(</span>
<span id="cb155-5"><a href="simple-linear-regression.html#cb155-5"></a>    <span class="dt">white =</span> <span class="kw">ifelse</span>(</span>
<span id="cb155-6"><a href="simple-linear-regression.html#cb155-6"></a>      RAC1P_label <span class="op">==</span><span class="st"> &quot;White alone&quot;</span>,</span>
<span id="cb155-7"><a href="simple-linear-regression.html#cb155-7"></a>      <span class="dv">1</span>,</span>
<span id="cb155-8"><a href="simple-linear-regression.html#cb155-8"></a>      <span class="dv">0</span></span>
<span id="cb155-9"><a href="simple-linear-regression.html#cb155-9"></a>    )</span>
<span id="cb155-10"><a href="simple-linear-regression.html#cb155-10"></a>  )</span></code></pre></div>
<p>Notice how we <code>filter(SPORDER == 1)</code> given the knowledge that the first listed individual in the questionnaire is the “householder”, and then create a new field <code>white</code> with a binary <code>1</code> or <code>0</code> based on <code>RAC1P_label</code>. If we try to plot this as a scatter plot, we won’t find the result particularly clear or compelling:</p>
<div class="sourceCode" id="cb156"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb156-1"><a href="simple-linear-regression.html#cb156-1"></a><span class="kw">ggplot</span>(</span>
<span id="cb156-2"><a href="simple-linear-regression.html#cb156-2"></a>  <span class="dt">data =</span> bay_pums_regression,</span>
<span id="cb156-3"><a href="simple-linear-regression.html#cb156-3"></a>  <span class="kw">aes</span>(</span>
<span id="cb156-4"><a href="simple-linear-regression.html#cb156-4"></a>      <span class="dt">x =</span> white,</span>
<span id="cb156-5"><a href="simple-linear-regression.html#cb156-5"></a>      <span class="dt">y =</span> HINCP</span>
<span id="cb156-6"><a href="simple-linear-regression.html#cb156-6"></a>    )</span>
<span id="cb156-7"><a href="simple-linear-regression.html#cb156-7"></a>) <span class="op">+</span></span>
<span id="cb156-8"><a href="simple-linear-regression.html#cb156-8"></a><span class="st">  </span><span class="kw">geom_point</span>()<span class="op">+</span></span>
<span id="cb156-9"><a href="simple-linear-regression.html#cb156-9"></a><span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="dt">se =</span> F)</span></code></pre></div>
<p><img src="course_files/figure-html/unnamed-chunk-121-1.png" width="672" /></p>
<p>The points are too smashed together given the <code>y-axis</code> spread for us to see where the center of gravity of each line of data is. Nonetheless, you might recognize that the essence of this analysis is a comparison of the average household income for non-White households (<code>white = 0</code>) vs. “White” households (<code>white = 1</code>), and the regression line simply connects the dots between these two averages to minimize SSR. The specific math here could be worked out in a more straightforward manner, but <code>lm()</code> will be key when expanding to multiple regression.</p>
<p>The results of <code>lm()</code> will provide us a clearer picture of whether there is a positive or negative relationship between <code>x</code> and <code>y</code>, and whether that relationship is statistically significant. Note the additional argument provided, <code>weights = WGTP</code>, which you can imagine <code>lm()</code> using to make the appropriate number of copies of each row of data to represent the full population.</p>
<div class="sourceCode" id="cb157"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb157-1"><a href="simple-linear-regression.html#cb157-1"></a>model_pums &lt;-<span class="st"> </span><span class="kw">lm</span>(HINCP <span class="op">~</span><span class="st"> </span>white, bay_pums_regression, <span class="dt">weights =</span> WGTP)</span>
<span id="cb157-2"><a href="simple-linear-regression.html#cb157-2"></a></span>
<span id="cb157-3"><a href="simple-linear-regression.html#cb157-3"></a><span class="kw">summary</span>(model_pums)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = HINCP ~ white, data = bay_pums_regression, weights = WGTP)
## 
## Weighted Residuals:
##      Min       1Q   Median       3Q      Max 
## -1732281  -312457   -78978   136203 11446499 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 119093.6      552.0  215.77   &lt;2e-16 ***
## white        20504.6      724.9   28.29   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 589600 on 138437 degrees of freedom
## Multiple R-squared:  0.005746,   Adjusted R-squared:  0.005739 
## F-statistic:   800 on 1 and 138437 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>In the results, note that the <code>y-intercept</code> of the regression line is $119,094, and the slope (or regression coefficient) is $20,505. In other words, all else being equal, a household being White seems to be associated with that household also having about $20K more income on average than a counterpart non-White household, which seems to have an average household income of about $120K. This relationship is statistically significant (p-value close to 0), which is to say that we should reject the null hypothesis that there is no relationship between White-ness and household income. But at the same time, the variable of White-ness explains less than 1% of the variation in household income overall (as can be seen in the vertical spread of data in the scatter plot), which is to say that you’d be making a very poor bet if you were trying to exactly predict income based on information about White-ness alone. And lastly, once again, none of these claims should be construed as claims about the causal relationship between White-ness and income (though we may very well find other ways to test for causality through experiments or more sophisticated analyses).</p>
<p>As a last demonstration for this section, let’s see what simple linear regression may tell us if we apply it to time series data, like the PG&amp;E data we’ve used before. The major problem is seasonality, which a linear regression is not inherently designed to deal with. However, it would be possible to investigate a particular slice of data, like comparing only Septembers with each other across the years, and if there really is a general trend up or down through the years, we’d be able to describe that trend with a regression line and potentially use it to predict future Septembers.</p>
<p>In the demonstration below, I’ll set up data for all months from 2013 to now (you can replicate this if you download all the data from the PG&amp;E site, but beware of a few manual corrections you need to make where PG&amp;E simply has poor quality control on its own field names). Then I’ll compute a total <code>AVERAGEKWH</code> for customers in the PG&amp;E territory each month and plot the results. We’ll see what the regression analysis gives us if we apply it directly to the entire dataset.</p>
<div class="sourceCode" id="cb159"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb159-1"><a href="simple-linear-regression.html#cb159-1"></a>years &lt;-<span class="st"> </span><span class="dv">2013</span><span class="op">:</span><span class="dv">2019</span></span>
<span id="cb159-2"><a href="simple-linear-regression.html#cb159-2"></a>quarters &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">:</span><span class="dv">4</span></span>
<span id="cb159-3"><a href="simple-linear-regression.html#cb159-3"></a></span>
<span id="cb159-4"><a href="simple-linear-regression.html#cb159-4"></a>pge_data &lt;-<span class="st"> </span><span class="ot">NULL</span></span>
<span id="cb159-5"><a href="simple-linear-regression.html#cb159-5"></a></span>
<span id="cb159-6"><a href="simple-linear-regression.html#cb159-6"></a><span class="cf">for</span>(year <span class="cf">in</span> years) {</span>
<span id="cb159-7"><a href="simple-linear-regression.html#cb159-7"></a>  <span class="cf">for</span>(quarter <span class="cf">in</span> quarters) {</span>
<span id="cb159-8"><a href="simple-linear-regression.html#cb159-8"></a>      </span>
<span id="cb159-9"><a href="simple-linear-regression.html#cb159-9"></a>    filename &lt;-<span class="st"> </span></span>
<span id="cb159-10"><a href="simple-linear-regression.html#cb159-10"></a><span class="st">      </span><span class="kw">paste0</span>(</span>
<span id="cb159-11"><a href="simple-linear-regression.html#cb159-11"></a>        <span class="st">&quot;pge/PGE_&quot;</span>,</span>
<span id="cb159-12"><a href="simple-linear-regression.html#cb159-12"></a>        year,</span>
<span id="cb159-13"><a href="simple-linear-regression.html#cb159-13"></a>        <span class="st">&quot;_Q&quot;</span>,</span>
<span id="cb159-14"><a href="simple-linear-regression.html#cb159-14"></a>        quarter,</span>
<span id="cb159-15"><a href="simple-linear-regression.html#cb159-15"></a>        <span class="st">&quot;_ElectricUsageByZip.csv&quot;</span></span>
<span id="cb159-16"><a href="simple-linear-regression.html#cb159-16"></a>      )</span>
<span id="cb159-17"><a href="simple-linear-regression.html#cb159-17"></a>    </span>
<span id="cb159-18"><a href="simple-linear-regression.html#cb159-18"></a>    temp &lt;-<span class="st"> </span><span class="kw">read_csv</span>(filename)</span>
<span id="cb159-19"><a href="simple-linear-regression.html#cb159-19"></a>    </span>
<span id="cb159-20"><a href="simple-linear-regression.html#cb159-20"></a>    pge_data &lt;-<span class="st"> </span></span>
<span id="cb159-21"><a href="simple-linear-regression.html#cb159-21"></a><span class="st">      </span><span class="kw">rbind</span>(pge_data,temp)</span>
<span id="cb159-22"><a href="simple-linear-regression.html#cb159-22"></a>      </span>
<span id="cb159-23"><a href="simple-linear-regression.html#cb159-23"></a>  }</span>
<span id="cb159-24"><a href="simple-linear-regression.html#cb159-24"></a>}</span>
<span id="cb159-25"><a href="simple-linear-regression.html#cb159-25"></a></span>
<span id="cb159-26"><a href="simple-linear-regression.html#cb159-26"></a>pge_avg_kwh &lt;-</span>
<span id="cb159-27"><a href="simple-linear-regression.html#cb159-27"></a><span class="st">  </span>pge_data <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb159-28"><a href="simple-linear-regression.html#cb159-28"></a><span class="st">  </span><span class="kw">filter</span>(CUSTOMERCLASS <span class="op">==</span><span class="st"> &quot;Elec- Residential&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb159-29"><a href="simple-linear-regression.html#cb159-29"></a><span class="st">  </span><span class="kw">group_by</span>(YEAR, MONTH) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb159-30"><a href="simple-linear-regression.html#cb159-30"></a><span class="st">  </span><span class="kw">summarize</span>(</span>
<span id="cb159-31"><a href="simple-linear-regression.html#cb159-31"></a>    <span class="dt">TOTALCUSTOMERS =</span> <span class="kw">sum</span>(TOTALCUSTOMERS, <span class="dt">na.rm =</span> T),</span>
<span id="cb159-32"><a href="simple-linear-regression.html#cb159-32"></a>    <span class="dt">TOTALMONTHLYKWH =</span> <span class="kw">sum</span>(TOTALKWH, <span class="dt">na.rm =</span> T)</span>
<span id="cb159-33"><a href="simple-linear-regression.html#cb159-33"></a>  ) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb159-34"><a href="simple-linear-regression.html#cb159-34"></a><span class="st">  </span><span class="kw">mutate</span>(</span>
<span id="cb159-35"><a href="simple-linear-regression.html#cb159-35"></a>    <span class="dt">AVGMONTHLYKWH =</span> TOTALMONTHLYKWH<span class="op">/</span>TOTALCUSTOMERS,</span>
<span id="cb159-36"><a href="simple-linear-regression.html#cb159-36"></a>    <span class="dt">DATE =</span> </span>
<span id="cb159-37"><a href="simple-linear-regression.html#cb159-37"></a>      <span class="kw">paste</span>(</span>
<span id="cb159-38"><a href="simple-linear-regression.html#cb159-38"></a>        YEAR,</span>
<span id="cb159-39"><a href="simple-linear-regression.html#cb159-39"></a>        MONTH, </span>
<span id="cb159-40"><a href="simple-linear-regression.html#cb159-40"></a>        <span class="st">&quot;01&quot;</span>,</span>
<span id="cb159-41"><a href="simple-linear-regression.html#cb159-41"></a>        <span class="dt">sep=</span><span class="st">&quot;-&quot;</span></span>
<span id="cb159-42"><a href="simple-linear-regression.html#cb159-42"></a>      ) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as.Date</span>()</span>
<span id="cb159-43"><a href="simple-linear-regression.html#cb159-43"></a>  )</span>
<span id="cb159-44"><a href="simple-linear-regression.html#cb159-44"></a></span>
<span id="cb159-45"><a href="simple-linear-regression.html#cb159-45"></a>pge_avg_kwh <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb159-46"><a href="simple-linear-regression.html#cb159-46"></a><span class="st">  </span><span class="kw">ggplot</span>(</span>
<span id="cb159-47"><a href="simple-linear-regression.html#cb159-47"></a>    <span class="kw">aes</span>(</span>
<span id="cb159-48"><a href="simple-linear-regression.html#cb159-48"></a>      <span class="dt">x =</span> DATE,</span>
<span id="cb159-49"><a href="simple-linear-regression.html#cb159-49"></a>      <span class="dt">y =</span> AVGMONTHLYKWH</span>
<span id="cb159-50"><a href="simple-linear-regression.html#cb159-50"></a>    )</span>
<span id="cb159-51"><a href="simple-linear-regression.html#cb159-51"></a>  ) <span class="op">+</span></span>
<span id="cb159-52"><a href="simple-linear-regression.html#cb159-52"></a><span class="st">  </span><span class="kw">geom_line</span>() <span class="op">+</span><span class="st"> </span></span>
<span id="cb159-53"><a href="simple-linear-regression.html#cb159-53"></a><span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>) <span class="op">+</span></span>
<span id="cb159-54"><a href="simple-linear-regression.html#cb159-54"></a><span class="st">  </span><span class="kw">labs</span>(</span>
<span id="cb159-55"><a href="simple-linear-regression.html#cb159-55"></a>    <span class="dt">x =</span> <span class="st">&quot;&quot;</span>,</span>
<span id="cb159-56"><a href="simple-linear-regression.html#cb159-56"></a>    <span class="dt">y =</span> <span class="st">&quot;Average kBTU/Customer&quot;</span>,</span>
<span id="cb159-57"><a href="simple-linear-regression.html#cb159-57"></a>    <span class="dt">title =</span> <span class="st">&quot;Residential Electricity Consumption in PG&amp;E Territories&quot;</span></span>
<span id="cb159-58"><a href="simple-linear-regression.html#cb159-58"></a>  )</span></code></pre></div>
<p><img src="course_files/figure-html/unnamed-chunk-123-1.png" width="672" /></p>
<p>Notice that there is a slight downward trend through the seasonality of the monthly data. Let’s see what <code>lm()</code> reports out:</p>
<div class="sourceCode" id="cb160"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb160-1"><a href="simple-linear-regression.html#cb160-1"></a>model_pge &lt;-<span class="st"> </span><span class="kw">lm</span>(AVGMONTHLYKWH <span class="op">~</span><span class="st"> </span>DATE, pge_avg_kwh)</span>
<span id="cb160-2"><a href="simple-linear-regression.html#cb160-2"></a></span>
<span id="cb160-3"><a href="simple-linear-regression.html#cb160-3"></a><span class="kw">summary</span>(model_pge)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = AVGMONTHLYKWH ~ DATE, data = pge_avg_kwh)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -117.17  -70.87  -13.91   62.00  177.81 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 973.44834  202.82178   4.800 7.05e-06 ***
## DATE         -0.02599    0.01194  -2.176   0.0324 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 80.77 on 82 degrees of freedom
## Multiple R-squared:  0.05459,    Adjusted R-squared:  0.04306 
## F-statistic: 4.735 on 1 and 82 DF,  p-value: 0.03244</code></pre>
<p>Notice that an increase of <code>DATE</code> by one unit appears to be associated with a reduction of <code>AVGMONTHLYKWH</code> by -0.0259851 (with a p-value in the 0.01-0.05 range). The <code>DATE</code> field, as a Date-type object, can be automatically converted to numeric values, which is reported out as days since January 1, 1970 (try this out in the Console: <code>Sys.Date() %&gt;% as.numeric()</code>). So, that’s how we know to interpret the regression coefficient as incrementing by days in the <code>x-axis</code>. If we wanted to report this out with more interpretable numbers, we could multiply both sides by 365 and say that every additional year seems to be associated with a reduction in average monthly customer electricity usage of about -9.5 kWh.</p>
<p>We can actually plot <code>model_pge$residuals</code> as well:</p>
<div class="sourceCode" id="cb162"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb162-1"><a href="simple-linear-regression.html#cb162-1"></a>pge_avg_kwh <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb162-2"><a href="simple-linear-regression.html#cb162-2"></a><span class="st">  </span><span class="kw">ggplot</span>(</span>
<span id="cb162-3"><a href="simple-linear-regression.html#cb162-3"></a>    <span class="kw">aes</span>(</span>
<span id="cb162-4"><a href="simple-linear-regression.html#cb162-4"></a>      <span class="dt">x =</span> DATE,</span>
<span id="cb162-5"><a href="simple-linear-regression.html#cb162-5"></a>      <span class="dt">y =</span> model_pge<span class="op">$</span>residuals</span>
<span id="cb162-6"><a href="simple-linear-regression.html#cb162-6"></a>    )</span>
<span id="cb162-7"><a href="simple-linear-regression.html#cb162-7"></a>  ) <span class="op">+</span></span>
<span id="cb162-8"><a href="simple-linear-regression.html#cb162-8"></a><span class="st">  </span><span class="kw">geom_line</span>() <span class="op">+</span><span class="st"> </span></span>
<span id="cb162-9"><a href="simple-linear-regression.html#cb162-9"></a><span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="dt">se =</span> F) <span class="op">+</span></span>
<span id="cb162-10"><a href="simple-linear-regression.html#cb162-10"></a><span class="st">  </span><span class="kw">labs</span>(</span>
<span id="cb162-11"><a href="simple-linear-regression.html#cb162-11"></a>    <span class="dt">x =</span> <span class="st">&quot;&quot;</span>,</span>
<span id="cb162-12"><a href="simple-linear-regression.html#cb162-12"></a>    <span class="dt">y =</span> <span class="st">&quot;Average kBTU/Customer&quot;</span>,</span>
<span id="cb162-13"><a href="simple-linear-regression.html#cb162-13"></a>    <span class="dt">title =</span> <span class="st">&quot;Residuals from previous regression&quot;</span></span>
<span id="cb162-14"><a href="simple-linear-regression.html#cb162-14"></a>  )</span></code></pre></div>
<p><img src="course_files/figure-html/unnamed-chunk-125-1.png" width="672" /></p>
<p>In a way, we’ve essentially separated out two trends in the PG&amp;E data. The residuals still show seasonality based on different energy usage throughout the months. But the regression line is the undercurrent of slow, gradual reduction in average energy usage, which could be reduced consumption behavior or energy efficiency improvements or both.</p>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="monte-carlo-simulations.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="sampling-bias.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": false,
"twitter": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": false
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": null,
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "none",
"scroll_highlight": true
},
"toolbar": {
"position": "fixed"
},
"search": false,
"info": false
});
});
</script>

</body>

</html>
